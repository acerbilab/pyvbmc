[Options]
# Explicit noise handling
uncertaintyhandling = []
# Array with indices of integer variables
integervars = []
# Display
display = "iter"
# Base observation noise magnitude (standard deviation)
noisesize = []
# Max number of consecutive repeated measurements for noisy inputs
maxrepeatedobservations = 0
# Multiplicative discount True acquisition fcn to repeat measurement at the same location
repeatedacqdiscount = 1
# Number of initial target fcn evals
funevalstart = np.maximum(D, 10)
# Base step size for stochastic gradient descent
sgdstepsize = 0.005
# Skip active sampling the first iteration after warmup
skipactivesamplingafterwarmup = False
# Use ranking criterion to pick best non-converged solution
rankcriterion = True
# Required stable iterations to switch entropy approximation
tolstableentropyiters = 6
# Use variable component means for variational posterior
variablemeans = True
# Use variable mixture weight for variational posterior
variableweights = True
# Penalty multiplier for small mixture weights
weightpenalty = 0.1
# Run in diagnostics mode get additional info
diagnostics = False
# Output function
outputfcn = []
# Fraction of allowed exceptions when computing iteration stability
tolstableexcptfrac = 0.2
# Evaluated fcn values at X0
fvals = []
# Use Optimization Toolbox (if empty determine at runtime)
optimtoolbox = []
# Weighted proposal fcn for uncertainty search
proposalfcn = []
# Automatic nonlinear rescaling of variables
nonlinearscaling = True
# Fast search acquisition fcn(s)
searchacqfcn = "@acqf_vbmc"
# Samples for fast acquisition fcn eval per new point
nssearch = 2 ** 13
# Total samples for preliminary Monte Carlo approx. of the entropy
nsentfast = 0