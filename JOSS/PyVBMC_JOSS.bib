@article{acerbi_variational_2018,
  title={{V}ariational {B}ayesian {M}onte {C}arlo},
  author={Acerbi, Luigi},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  pages={8222--8232},
  year={2018}
}

@article{acerbi_variational_2020,
  title={{V}ariational {B}ayesian {M}onte {C}arlo with noisy likelihoods},
  author={Acerbi, Luigi},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={8211--8222},
  year={2020}
}

@article{acerbi_exploration_2019,
  title={An Exploration of Acquisition and Mean Functions in {V}ariational {B}ayesian {M}onte {C}arlo},
  author={Acerbi, Luigi},
  journal={PMLR},
  volume={96},
  pages={1--10},
  year={2019}
}

@book{rasmussen_gaussian_2006,
	address = {Cambridge, Mass},
	series = {Adaptive computation and machine learning},
	title = {{Gaussian} processes for machine learning},
	isbn = {978-0-262-18253-9},
	language = {en},
	publisher = {MIT Press},
	author = {Rasmussen, Carl Edward and Williams, Christopher K. I.},
	year = {2006},
	note = {OCLC: ocm61285753},
	keywords = {Data processing, Gaussian processes, Machine learning, Mathematical models},
}

@book{murphy_probabilistic_2023,
	title = {Probabilistic {Machine} {Learning}: {Advanced} {Topics}},
	url = {http://probml.github.io/book2},
	publisher = {MIT Press},
	author = {Murphy, Kevin P.},
	year = {2023},
}

@book{garnett_bayesian_2023,
  author    = {Garnett, Roman},
  title     = {{Bayesian Optimization}},
  year      = {2023},
  publisher = {Cambridge University Press},
  note      = {to appear}
}

@misc{gammal_fast_2022,
	title = {Fast and robust {Bayesian} inference using {Gaussian} processes with {GPry}},
	url = {http://arxiv.org/abs/2211.02045},
	abstract = {We present the GPry algorithm for fast Bayesian inference of general (non-Gaussian) posteriors with a moderate number of parameters. GPry does not need any pre-training, special hardware such as GPUs, and is intended as a drop-in replacement for traditional Monte Carlo methods for Bayesian inference. Our algorithm is based on generating a Gaussian Process surrogate model of the log-posterior, aided by a Support Vector Machine classiﬁer that excludes extreme or non-ﬁnite values. An active learning scheme allows us to reduce the number of required posterior evaluations by two orders of magnitude compared to traditional Monte Carlo inference. Our algorithm allows for parallel evaluations of the posterior at optimal locations, further reducing wall-clock times. We signiﬁcantly improve performance using properties of the posterior in our active learning scheme and for the deﬁnition of the GP prior. In particular we account for the expected dynamical range of the posterior in diﬀerent dimensionalities. We test our model against a number of synthetic and cosmological examples. GPry outperforms traditional Monte Carlo methods when the evaluation time of the likelihood (or the calculation of theoretical observables) is of the order of seconds; for evaluation times of over a minute it can perform inference in days that would take months using traditional methods. GPry is distributed as an open source Python package (pip install gpry) and can also be found at https://github.com/jonaselgammal/GPry.},
	language = {en},
	urldate = {2023-02-22},
	publisher = {arXiv},
	author = {Gammal, Jonas El and Schöneberg, Nils and Torrado, Jesús and Fidler, Christian},
	month = dec,
	year = {2022},
	note = {arXiv:2211.02045 [astro-ph, stat]},
	keywords = {Statistics - Machine Learning, Statistics - Methodology, Astrophysics - Cosmology and Nongalactic Astrophysics, Astrophysics - Instrumentation and Methods for Astrophysics},
}

@article {stine_differentiating_2020,
article_type = {journal},
title = {Differentiating between integration and non-integration strategies in perceptual decision making},
author = {Stine, Gabriel M and Zylberberg, Ariel and Ditterich, Jochen and Shadlen, Michael N},
editor = {Wyart, Valentin and Frank, Michael J and Wyart, Valentin and Usher, Marius},
volume = 9,
year = 2020,
month = {apr},
pub_date = {2020-04-27},
pages = {e55365},
citation = {eLife 2020;9:e55365},
doi = {10.7554/eLife.55365},
url = {https://doi.org/10.7554/eLife.55365},
abstract = {Many tasks used to study decision-making encourage subjects to integrate evidence over time. Such tasks are useful to understand how the brain operates on multiple samples of information over prolonged timescales, but only if subjects actually integrate evidence to form their decisions. We explored the behavioral observations that corroborate evidence-integration in a number of task-designs. Several commonly accepted signs of integration were also predicted by non-integration strategies. Furthermore, an integration model could fit data generated by non-integration models. We identified the features of non-integration models that allowed them to mimic integration and used these insights to design a motion discrimination task that disentangled the models. In human subjects performing the task, we falsified a non-integration strategy in each and confirmed prolonged integration in all but one subject. The findings illustrate the difficulty of identifying a decision-maker’s strategy and support solutions to achieve this goal.},
keywords = {decision making, evidence accumulation, perceptual decisions, behavioral modeling},
journal = {eLife},
issn = {2050-084X},
publisher = {eLife Sciences Publications, Ltd},
}

@article{che_application_2021,
title = {Application of Kriging and {Variational Bayesian Monte Carlo} method for improved prediction of doped UO2 fission gas release},
journal = {Annals of Nuclear Energy},
volume = {153},
pages = {108046},
year = {2021},
issn = {0306-4549},
doi = {https://doi.org/10.1016/j.anucene.2020.108046},
url = {https://www.sciencedirect.com/science/article/pii/S0306454920307428},
author = {Yifeng Che and Xu Wu and Giovanni Pastore and Wei Li and Koroush Shirvan},
keywords = {Doped fuel, Variational Bayesian Monte Carlo (VBMC), Bayesian inference, Kriging, Principal Component Analysis (PCA)},
abstract = {One of the advanced nuclear fuel concepts for current commercial water-cooled reactors focuses on microstructural modification of UO2 fuel via dopants. Dopants can effectively promote grain growth and suppress fission gas release (FGR), a key parameter that dictates the overall nuclear fuel performance. This work improves the BISON FGR model for chromia/alumina-doped UO2 fuel through statistical calibration with in-reactor experimental data. The high computing cost and nonintrusive nature of BISON limit the application of conventional techniques under the Bayesian framework. Dimensionality reduction is performed using principal component analysis (PCA) to deal with the FGR time series data. Kriging is used as metamodel of BISON to reduce the computing cost. A novel optimization framework, Variational Bayesian Monte Carlo (VBMC) is demonstrated as a low-cost nonintrusive approach for Bayesian calibration. The performance of VBMC is compared to the conventional statistical Markov Chain Monte Carlo (MCMC) sampling showing similar accuracy but superior efficiency.}
}

@Article{hao_application_2022,
author={Hao, Wang
and Duan, Rui
and Yang, Kunde},
title={Application of Dual-Source Modal Dispersion and {Variational Bayesian Monte Carlo} Method for Local Geoacoustic Inversion in Weakly Range-Dependent Shallow Water},
journal={Acoustics Australia},
year={2022},
month={Aug},
day={25},
abstract={Most of the continental shelf area is a weakly range-dependent shallow-water environment. Compared with range-independent Bayesian geoacoustic inversion, range-dependent inversion usually has problems with the complex forward model and low efficiency for posterior analysis. According to the adiabatic normal-mode theory, the weakly range-dependent shallow-water environment can be divided into a series of range-independent segments; thus, this paper proposes a dual-source modal dispersion inversion method for local geoacoustic parameters of a segment based on a range-independent forward model. In addition, considering that the computational cost of the forward model limits the application of sampling-based methods for posterior analysis, a novel approximate variational inference, namely variational Bayesian Monte Carlo, is applied in this study. It has superior efficiency and shows similar accuracy compared with Markov Chain Monte Carlo sampling. This work is demonstrated in the shallow-water experiment in the continental shelf area of the East China Sea, and the results indicate that the local and range-dependent geoacoustic parameters are well-estimated.},
issn={1839-2571},
doi={10.1007/s40857-022-00277-2},
url={https://doi.org/10.1007/s40857-022-00277-2}
}

@Article{demetriades_interrogating_2022,
AUTHOR = {Demetriades, Marios and Zivanovic, Marko and Hadjicharalambous, Myrianthi and Ioannou, Eleftherios and Ljujic, Biljana and Vucicevic, Ksenija and Ivosevic, Zeljko and Dagovic, Aleksandar and Milivojevic, Nevena and Kokkinos, Odysseas and Bauer, Roman and Vavourakis, Vasileios},
TITLE = {Interrogating and Quantifying In Vitro Cancer Drug Pharmacodynamics via Agent-Based and {Bayesian} {Monte Carlo} Modelling},
JOURNAL = {Pharmaceutics},
VOLUME = {14},
YEAR = {2022},
NUMBER = {4},
ARTICLE-NUMBER = {749},
URL = {https://www.mdpi.com/1999-4923/14/4/749},
PubMedID = {35456583},
ISSN = {1999-4923},
ABSTRACT = {The effectiveness of chemotherapy in cancer cell regression is often limited by drug resistance, toxicity, and neoplasia heterogeneity. However, due to the significant complexities entailed by the many cancer growth processes, predicting the impact of interference and symmetry-breaking mechanisms is a difficult problem. To quantify and understand more about cancer drug pharmacodynamics, we combine in vitro with in silico cancer models. The anti-proliferative action of selected cytostatics is interrogated on human colorectal and breast adenocarcinoma cells, while an agent-based computational model is employed to reproduce experiments and shed light on the main therapeutic mechanisms of each chemotherapeutic agent. Multiple drug administration scenarios on each cancer cell line are simulated by varying the drug concentration, while a Bayesian-based method for model parameter optimisation is employed. Our proposed procedure of combining in vitro cancer drug screening with an in silico agent-based model successfully reproduces the impact of chemotherapeutic drugs in cancer growth behaviour, while the mechanisms of action of each drug are characterised through model-derived probabilities of cell apoptosis and division. We suggest that our approach could form the basis for the prospective generation of experimentally-derived and model-optimised pharmacological variables towards personalised cancer therapy.},
DOI = {10.3390/pharmaceutics14040749}
}

@inproceedings{gunter_sampling_2014,
 author = {Gunter, Tom and Osborne, Michael A and Garnett, Roman and Hennig, Philipp and Roberts, Stephen J},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {Z. Ghahramani and M. Welling and C. Cortes and N. Lawrence and K.Q. Weinberger},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Sampling for Inference in Probabilistic Models with Fast {Bayesian} Quadrature},
 url = {https://proceedings.neurips.cc/paper/2014/file/e94f63f579e05cb49c05c2d050ead9c0-Paper.pdf},
 volume = {27},
 year = {2014}
}

@inproceedings{osborne_active_2012,
 author = {Osborne, Michael and Garnett, Roman and Ghahramani, Zoubin and Duvenaud, David K and Roberts, Stephen J and Rasmussen, Carl},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {F. Pereira and C.J. Burges and L. Bottou and K.Q. Weinberger},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Active Learning of Model Evidence Using {Bayesian} Quadrature},
 url = {https://proceedings.neurips.cc/paper/2012/file/6364d3f0f495b6ab9dcf8d3b5c6e0b01-Paper.pdf},
 volume = {25},
 year = {2012}
}

@inproceedings{kandasamy_bayesian_2015,
author = {Kandasamy, Kirthevasan and Schneider, Jeff and P\'{o}czos, Barnab\'{a}s},
title = {{Bayesian} Active Learning for Posterior Estimation},
year = {2015},
isbn = {9781577357384},
publisher = {AAAI Press},
abstract = {This paper studies active posterior estimation in a Bayesian setting when the likelihood is expensive to evaluate. Existing techniques for posterior estimation are based on generating samples representative of the posterior. Such methods do not consider efficiency in terms of likelihood evaluations. In order to be query efficient we treat posterior estimation in an active regression framework. We propose two myopic query strategies to choose where to evaluate the likelihood and implement them using Gaussian processes. Via experiments on a series of synthetic and real examples we demonstrate that our approach is significantly more query efficient than existing techniques and other heuristics for posterior estimation.},
booktitle = {Proceedings of the 24th International Conference on Artificial Intelligence},
pages = {3605–3611},
numpages = {7},
location = {Buenos Aires, Argentina},
series = {IJCAI'15}
}

@article{wang_adaptive_2018,
    author = {Wang, Hongqiao and Li, Jinglai},
    title = {Adaptive {Gaussian} Process Approximation for {Bayesian} Inference with Expensive Likelihood Functions},
    journal = {Neural Computation},
    volume = {30},
    number = {11},
    pages = {3072-3094},
    year = {2018},
    month = {11},
    abstract = "{We consider Bayesian inference problems with computationally intensive likelihood functions. We propose a Gaussian process (GP)–based method to approximate the joint distribution of the unknown parameters and the data, built on recent work (Kandasamy, Schneider, \\&amp; Póczos, 2015). In particular, we write the joint density approximately as a product of an approximate posterior density and an exponentiated GP surrogate. We then provide an adaptive algorithm to construct such an approximation, where an active learning method is used to choose the design points. With numerical examples, we illustrate that the proposed method has competitive performance against existing approaches for Bayesian computation.}",
    issn = {0899-7667},
    doi = {10.1162/neco_a_01127},
    url = {https://doi.org/10.1162/neco\_a\_01127},
    eprint = {https://direct.mit.edu/neco/article-pdf/30/11/3072/1047403/neco\_a\_01127.pdf},
}

@inproceedings{paleyes_emulation_2019,
	author = {Paleyes, Andrei and Pullin, Mark and Mahsereci, Maren and Lawrence, Neil and González, Javier},
	title = {Emulation of physical processes with {Emukit}},
	booktitle = {Second Workshop on Machine Learning and the Physical Sciences, NeurIPS},
	year = {2019}
}

@article{jarvenpaa_parallel_2021,
author = {Marko J{\"a}rvenp{\"a}{\"a} and Michael U. Gutmann and Aki Vehtari and Pekka Marttinen},
title = {Parallel {Gaussian} Process Surrogate {Bayesian} Inference with Noisy Likelihood Evaluations},
volume = {16},
journal = {Bayesian Analysis},
number = {1},
publisher = {International Society for Bayesian Analysis},
pages = {147 -- 178},
keywords = {expensive likelihoods, Gaussian processes, likelihood-free inference, parallel computing, sequential experiment design, surrogate modelling},
year = {2021},
doi = {10.1214/20-BA1200},
URL = {https://doi.org/10.1214/20-BA1200}
}

@article{ohagan_bayesian_1991,
title = {Bayes–Hermite quadrature},
journal = {Journal of Statistical Planning and Inference},
volume = {29},
number = {3},
pages = {245-260},
year = {1991},
issn = {0378-3758},
doi = {https://doi.org/10.1016/0378-3758(91)90002-V},
url = {https://www.sciencedirect.com/science/article/pii/037837589190002V},
author = {A. O'Hagan},
keywords = {Bayesian quadrature, numerical integration, Gaussian process, product rule, Gaussian quadrature},
abstract = {Bayesian quadrature treats the problem of numerical integration as one of statistical inference. A prior Gaussian process distribution is assumed for the integrand, observations arise from evaluating the integrand at selected points, and a posterior distribution is derived for the integrand and the integral. Methods are developed for quadrature in Rp. A particular application is integrating the posterior density arising from some other Bayesian analysis. Simulation results are presented, to show that the resulting Bayes–Hermite quadrature rules may perform better than the conventional Gauss–Hermite rules for this application. A key result is derived for product designs, which makes Bayesian quadrature practically useful for integrating in several dimensions. Although the method does not at present provide a solution to the more difficult problem of quadrature in high dimensions, it does seem to offer real improvements over existing methods in relatively low dimensions.}
}

@inproceedings{ghahramani_bayesian_2002,
 author = {Ghahramani, Zoubin and Rasmussen, Carl},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Becker and S. Thrun and K. Obermayer},
 pages = {},
 publisher = {MIT Press},
 title = {{Bayesian Monte Carlo}},
 url = {https://proceedings.neurips.cc/paper/2002/file/24917db15c4e37e421866448c9ab23d8-Paper.pdf},
 volume = {15},
 year = {2002}
}

@article{martin_computing_2020,
  title={Computing {Bayes}: {Bayesian} Computation from 1763 to the 21st Century},
  author={Gael M. Martin and David T. Frazier and Christian P. Robert},
  journal={arXiv: Computation},
  year={2020}
}

﻿@Article{harris_array_2020,
author={Harris, Charles R.
and Millman, K. Jarrod
and van der Walt, St{\'e}fan J.
and Gommers, Ralf
and Virtanen, Pauli
and Cournapeau, David
and Wieser, Eric
and Taylor, Julian
and Berg, Sebastian
and Smith, Nathaniel J.
and Kern, Robert
and Picus, Matti
and Hoyer, Stephan
and van Kerkwijk, Marten H.
and Brett, Matthew
and Haldane, Allan
and del R{\'i}o, Jaime Fern{\'a}ndez
and Wiebe, Mark
and Peterson, Pearu
and G{\'e}rard-Marchant, Pierre
and Sheppard, Kevin
and Reddy, Tyler
and Weckesser, Warren
and Abbasi, Hameer
and Gohlke, Christoph
and Oliphant, Travis E.},
title={Array programming with NumPy},
journal={Nature},
year={2020},
month={Sep},
day={01},
volume={585},
number={7825},
pages={357-362},
abstract={Array programming provides a powerful, compact and expressive syntax for accessing, manipulating and operating on data in vectors, matrices and higher-dimensional arrays. NumPy is the primary array programming library for the Python language. It has an essential role in research analysis pipelines in fields as diverse as physics, chemistry, astronomy, geoscience, biology, psychology, materials science, engineering, finance and economics. For example, in astronomy, NumPy was an important part of the software stack used in the discovery of gravitational waves1 and in the first imaging of a black hole2. Here we review how a few fundamental array concepts lead to a simple and powerful programming paradigm for organizing, exploring and analysing scientific data. NumPy is the foundation upon which the scientific Python ecosystem is constructed. It is so pervasive that several projects, targeting audiences with specialized needs, have developed their own NumPy-like interfaces and array objects. Owing to its central position in the ecosystem, NumPy increasingly acts as an interoperability layer between such array computation libraries and, together with its application programming interface (API), provides a flexible framework to support the next decade of scientific and industrial analysis.},
issn={1476-4687},
doi={10.1038/s41586-020-2649-2},
url={https://doi.org/10.1038/s41586-020-2649-2}
}

@article{foreman-mackey_corner_2016, doi = {10.21105/joss.00024}, url = {https://doi.org/10.21105/joss.00024}, year = {2016}, publisher = {The Open Journal}, volume = {1}, number = {2}, pages = {24}, author = {Daniel Foreman-Mackey}, title = {corner.py: Scatterplot matrices in {Python}}, journal = {Journal of Open Source Software} }
